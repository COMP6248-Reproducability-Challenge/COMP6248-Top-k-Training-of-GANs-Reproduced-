{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR_FID.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qHA9Gd4UA5tn"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from scipy import linalg\n",
        "from torch.nn.functional import adaptive_avg_pool2d\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED=42\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "batch_size = 128 # Batch size for training\n",
        "image_size = 64 # Image Size\n",
        "nc = 3 # Number of image channels\n",
        "nz = 100 # Size of generator input\n",
        "ngf = 64 # Number of feature maps in generator\n",
        "ndf = 64 # Number of feature maps in discriminator\n",
        "num_epochs = 1000 # Number of epochs \n",
        "# Learning rates for optimizers\n",
        "g_lr = 0.0001\n",
        "d_lr = 0.0004\n",
        "beta = 0.5 # Beta hyperparam for Adam optimizers\n",
        "ngpu=1"
      ],
      "metadata": {
        "id": "UIbmB1ibBOwv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizing input between -1 and 1\n",
        "transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0,0,0), (1,1,1)),])\n",
        "\n",
        "\n",
        "dataset = dset.CIFAR10(root='../input', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "tyg4LPRFBWIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Plot some training images\n",
        "real_images = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_images[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "metadata": {
        "id": "S7f66dG-BYwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "e-FjbKMnBjYk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights initialization\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "HDpdNpsxBmyD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Generator\n",
        "netG = Generator(ngpu).to(device)\n",
        "netG.apply(weights_init)\n",
        "print(netG)"
      ],
      "metadata": {
        "id": "lSY7ZXGoBpHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "lae3UVY2BrO0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ],
      "metadata": {
        "id": "sdNsWQ6ABwwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "# Label with smoothing\n",
        "real_label=0.9\n",
        "fake_label=0.1\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optim_D = optim.Adam(netD.parameters(), lr=d_lr, betas=(beta, 0.999))\n",
        "optim_G = optim.Adam(netG.parameters(), lr=g_lr, betas=(beta, 0.999))"
      ],
      "metadata": {
        "id": "XUBylyXrBy7F"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inception model to calculate FID\n",
        "class InceptionV3(nn.Module):\n",
        "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
        "\n",
        "    # Index of default block of inception to return,\n",
        "    # corresponds to output of final average pooling\n",
        "    DEFAULT_BLOCK_INDEX = 3\n",
        "\n",
        "    # Maps feature dimensionality to their output blocks indices\n",
        "    BLOCK_INDEX_BY_DIM = {\n",
        "        64: 0,   # First max pooling features\n",
        "        192: 1,  # Second max pooling featurs\n",
        "        768: 2,  # Pre-aux classifier features\n",
        "        2048: 3  # Final average pooling features\n",
        "    }\n",
        "\n",
        "    def __init__(self,\n",
        "                 output_blocks=[DEFAULT_BLOCK_INDEX],\n",
        "                 resize_input=True,\n",
        "                 normalize_input=True,\n",
        "                 requires_grad=False):\n",
        "        \n",
        "        super(InceptionV3, self).__init__()\n",
        "\n",
        "        self.resize_input = resize_input\n",
        "        self.normalize_input = normalize_input\n",
        "        self.output_blocks = sorted(output_blocks)\n",
        "        self.last_needed_block = max(output_blocks)\n",
        "\n",
        "        assert self.last_needed_block <= 3, \\\n",
        "            'Last possible output block index is 3'\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "\n",
        "        \n",
        "        inception = models.inception_v3(pretrained=True)\n",
        "\n",
        "        # Block 0: input to maxpool1\n",
        "        block0 = [\n",
        "            inception.Conv2d_1a_3x3,\n",
        "            inception.Conv2d_2a_3x3,\n",
        "            inception.Conv2d_2b_3x3,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        ]\n",
        "        self.blocks.append(nn.Sequential(*block0))\n",
        "\n",
        "        # Block 1: maxpool1 to maxpool2\n",
        "        if self.last_needed_block >= 1:\n",
        "            block1 = [\n",
        "                inception.Conv2d_3b_1x1,\n",
        "                inception.Conv2d_4a_3x3,\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block1))\n",
        "\n",
        "        # Block 2: maxpool2 to aux classifier\n",
        "        if self.last_needed_block >= 2:\n",
        "            block2 = [\n",
        "                inception.Mixed_5b,\n",
        "                inception.Mixed_5c,\n",
        "                inception.Mixed_5d,\n",
        "                inception.Mixed_6a,\n",
        "                inception.Mixed_6b,\n",
        "                inception.Mixed_6c,\n",
        "                inception.Mixed_6d,\n",
        "                inception.Mixed_6e,\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block2))\n",
        "\n",
        "        # Block 3: aux classifier to final avgpool\n",
        "        if self.last_needed_block >= 3:\n",
        "            block3 = [\n",
        "                inception.Mixed_7a,\n",
        "                inception.Mixed_7b,\n",
        "                inception.Mixed_7c,\n",
        "                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block3))\n",
        "\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = requires_grad\n",
        "\n",
        "    def forward(self, inp):\n",
        "        \"\"\"Get Inception feature maps\n",
        "        Parameters\n",
        "        ----------\n",
        "        inp : torch.autograd.Variable\n",
        "            Input tensor of shape Bx3xHxW. Values are expected to be in\n",
        "            range (0, 1)\n",
        "        Returns\n",
        "        -------\n",
        "        List of torch.autograd.Variable, corresponding to the selected output\n",
        "        block, sorted ascending by index\n",
        "        \"\"\"\n",
        "        outp = []\n",
        "        x = inp\n",
        "\n",
        "        if self.resize_input:\n",
        "            x = F.interpolate(x,\n",
        "                              size=(299, 299),\n",
        "                              mode='bilinear',\n",
        "                              align_corners=False)\n",
        "\n",
        "        if self.normalize_input:\n",
        "            x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n",
        "\n",
        "        for idx, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            if idx in self.output_blocks:\n",
        "                outp.append(x)\n",
        "\n",
        "            if idx == self.last_needed_block:\n",
        "                break\n",
        "\n",
        "        return outp\n",
        "    \n",
        "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
        "model = InceptionV3([block_idx])\n",
        "model=model.cuda()"
      ],
      "metadata": {
        "id": "3Q13teL4B1GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_activation_statistics(images,model,batch_size=128, dims=2048,\n",
        "                    cuda=False):\n",
        "    model.eval()\n",
        "    act=np.empty((len(images), dims))\n",
        "    \n",
        "    if cuda:\n",
        "        batch=images.cuda()\n",
        "    else:\n",
        "        batch=images\n",
        "    pred = model(batch)[0]\n",
        "\n",
        "        # If model output is not scalar, apply global spatial average pooling.\n",
        "        # This happens if you choose a dimensionality not equal 2048.\n",
        "    if pred.size(2) != 1 or pred.size(3) != 1:\n",
        "        pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
        "\n",
        "    act= pred.cpu().data.numpy().reshape(pred.size(0), -1)\n",
        "    \n",
        "    mu = np.mean(act, axis=0)\n",
        "    sigma = np.cov(act, rowvar=False)\n",
        "    return mu, sigma"
      ],
      "metadata": {
        "id": "4KTv2_x5B5WF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
        "    \"\"\"Numpy implementation of the Frechet Distance.\n",
        "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
        "    and X_2 ~ N(mu_2, C_2) is\n",
        "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
        "    \"\"\"\n",
        "\n",
        "    mu1 = np.atleast_1d(mu1)\n",
        "    mu2 = np.atleast_1d(mu2)\n",
        "\n",
        "    sigma1 = np.atleast_2d(sigma1)\n",
        "    sigma2 = np.atleast_2d(sigma2)\n",
        "\n",
        "    assert mu1.shape == mu2.shape, \\\n",
        "        'Training and test mean vectors have different lengths'\n",
        "    assert sigma1.shape == sigma2.shape, \\\n",
        "        'Training and test covariances have different dimensions'\n",
        "\n",
        "    diff = mu1 - mu2\n",
        "\n",
        "    \n",
        "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    if not np.isfinite(covmean).all():\n",
        "        msg = ('fid calculation produces singular product; '\n",
        "               'adding %s to diagonal of cov estimates') % eps\n",
        "        print(msg)\n",
        "        offset = np.eye(sigma1.shape[0]) * eps\n",
        "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "\n",
        "    \n",
        "    if np.iscomplexobj(covmean):\n",
        "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "            m = np.max(np.abs(covmean.imag))\n",
        "            raise ValueError('Imaginary component {}'.format(m))\n",
        "        covmean = covmean.real\n",
        "\n",
        "    tr_covmean = np.trace(covmean)\n",
        "\n",
        "    return (diff.dot(diff) + np.trace(sigma1) +\n",
        "            np.trace(sigma2) - 2 * tr_covmean)"
      ],
      "metadata": {
        "id": "td5hRbqRB8cF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fretchet(images_real,images_fake,model):\n",
        "     mu_1,std_1=calculate_activation_statistics(images_real,model,cuda=True)\n",
        "     mu_2,std_2=calculate_activation_statistics(images_fake,model,cuda=True)\n",
        "    \n",
        "     \"\"\"get fretched distance\"\"\"\n",
        "     fid_value = calculate_frechet_distance(mu_1, std_1, mu_2, std_2)\n",
        "     return fid_value"
      ],
      "metadata": {
        "id": "rQiR_wDBB-7l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generator Parameters:\",sum(p.numel() for p in netG.parameters() if p.requires_grad))\n",
        "print(\"Discriminator Parameters:\",sum(p.numel() for p in netD.parameters() if p.requires_grad))"
      ],
      "metadata": {
        "id": "BfzLDjn5CAz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "decay_rate = 0.99 # Decay rate by which k value reduces until min k value\n",
        "min_k = int(0.75*batch_size) #Min k value\n",
        "print(\"Min k val\", min_k)\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "for epoch in range(num_epochs):\n",
        "    k = batch_size # Initialize k to full batch size\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        \n",
        "\n",
        "        # Discriminator Update\n",
        "\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, device=device)        \n",
        "        real_cpu=0.9*real_cpu+0.1*torch.randn((real_cpu.size()), device=device)\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)        \n",
        "        fake=0.9*fake+0.1*torch.randn((fake.size()), device=device)\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        errD = errD_real + errD_fake\n",
        "        optim_D.step()\n",
        "\n",
        "        # Generator Update\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  \n",
        "        output = netD(fake).view(-1)\n",
        "        # print(\"Output before Sorting\", output)\n",
        "        if k > 0:\n",
        "          output = torch.sort(output, descending=True)\n",
        "        else:\n",
        "          output = torch.sort(output, descending=False)\n",
        "\n",
        "\n",
        "        output = output.values[:k]\n",
        "        klabel = torch.ones_like(output)\n",
        "        # print(\"Output after Sorting\", output)\n",
        "        errG = criterion(output, klabel)\n",
        "        D_G_z2 = output.mean().item()\n",
        "        \n",
        "        errG.backward()\n",
        "        optim_G.step()\n",
        "        # Updating k \n",
        "        k = int(k * decay_rate) \n",
        "        k = max(min_k, k)\n",
        "        # print(\"Updated k val\", k)\n",
        "       \n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fixed_noise = torch.randn(ngf, nz, 1, 1, device=device)\n",
        "                fake_display = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake_display, padding=2, normalize=True))         \n",
        "         \n",
        "            \n",
        "        iters += 1   \n",
        "    G_losses.append(errG.item())\n",
        "    D_losses.append(errD.item())     \n",
        "    fretchet_dist=calculate_fretchet(real_cpu,fake,model) \n",
        "    if ((epoch+1)%5==0):\n",
        "        \n",
        "        print('[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tFretchet_Distance: %.4f'\n",
        "                      % (epoch+1, num_epochs,\n",
        "                         errD.item(), errG.item(),fretchet_dist))\n",
        "        \n",
        "        \n",
        "        plt.figure(figsize=(8,8))\n",
        "        plt.axis(\"off\")\n",
        "        pictures=vutils.make_grid(fake_display[torch.randint(len(fake_display), (10,))],nrow=5,padding=2, normalize=True)\n",
        "        plt.imshow(np.transpose(pictures,(1,2,0)))\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "GGPiEqkBCDKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss during Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cbaq3tP8CGAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot genearted images\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w72GHVhq4MWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QwLD0MHG4STx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}