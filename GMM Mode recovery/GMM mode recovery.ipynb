{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GMM mode recovery.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1cCbEKG7TmpPukQWypzinLnSeodjArRrL","authorship_tag":"ABX9TyOP5zkCuQHLwAE6xbptDwif"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import jax\n","import jax.numpy as jnp\n","from jax.experimental.optimizers import adam\n","from jax.config import config\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from jax.nn import sigmoid\n","from jax.nn.initializers import normal\n","from jax.nn import leaky_relu, sigmoid\n","from jax.experimental import stax\n","from jax.example_libraries.stax import (BatchNorm, Conv, ConvTranspose, Dense,\n","                                   Tanh, Relu, Flatten, Sigmoid)\n","from jax.experimental.stax import (BatchNorm, Conv, ConvTranspose, Dense,\n","                                   Tanh, Relu, Flatten, Sigmoid)\n","from jax.experimental.optimizers import pack_optimizer_state, unpack_optimizer_state\n","from jax.example_libraries.optimizers import pack_optimizer_state, unpack_optimizer_state\n","import jax.random as random\n","\n","from jax.lax import sort\n","\n","from jax import value_and_grad, jit\n","from functools import partial\n","import pickle\n","import os\n","\n","finfo = jnp.finfo(jnp.float32)\n","EPS = finfo.eps\n","EPSNEG = finfo.epsneg\n","\n","import argparse\n","import time\n","\n","\n","def mlp_discriminator():\n","    model = stax.serial(\n","        Dense(out_dim=256), Relu,\n","        # BatchNorm(axis=(1,)),\n","        Dense(out_dim=256), Relu,\n","        # BatchNorm(axis=(1,)),\n","        Dense(out_dim=256), Relu,\n","        # BatchNorm(axis=(1,)),\n","        Dense(out_dim=256), Relu,\n","        # BatchNorm(axis=(1,)),\n","        Dense(1),\n","        # Sigmoid\n","    )\n","    return model\n","\n","\n","def mlp_generator_2d():\n","    model = stax.serial(\n","        Dense(out_dim=256), Relu,\n","        # BatchNorm(axis=(1,)),\n","        Dense(out_dim=256), Relu,\n","        # BatchNorm(axis=(1,)),\n","        Dense(out_dim=256), Relu,\n","        # BatchNorm(axis=(1,)),\n","        Dense(out_dim=256), Relu,\n","        # BatchNorm(axis=(1,)),\n","        Dense(2)\n","    )\n","    return model\n","class GAN:\n","  \n","\n","   \n","\n","    def __init__(self, d_creator, g_creator, d_opt_creator, g_opt_creator, loss_function):\n","\n","        d_init, d_apply = d_creator()\n","        g_init, g_apply = g_creator()\n","        (d_opt_init, d_opt_update, d_opt_get_params) = d_opt_creator()\n","        (g_opt_init, g_opt_update, g_opt_get_params) = g_opt_creator()\n","\n","        # self.creators = {'d_creator': d_creator,\n","        #                  'g_creator': g_creator,\n","        #                  'd_opt_creator': d_opt_creator,\n","        #                  'g_opt_creator': g_opt_creator\n","        #                  }\n","        self.d_creator = d_creator\n","        self.g_creator = g_creator\n","        self.d_opt_creator = d_opt_creator\n","        self.g_opt_creator = g_opt_creator\n","        self.d = {'init': d_init, 'apply': d_apply}\n","        self.g = {'init': g_init, 'apply': g_apply}\n","        self.d_opt = {'init': d_opt_init, 'update': d_opt_update, 'get_params': d_opt_get_params}\n","        self.g_opt = {'init': g_opt_init, 'update': g_opt_update, 'get_params': g_opt_get_params}\n","        self.loss_function = loss_function\n","        self.d_output_shape = None\n","        self.g_output_shape = None\n","        self.d_input_shape = None\n","        self.g_input_shape = None\n","        self.batch_size = None\n","\n","    def init(self, prng_d, prng_g, d_input_shape, g_input_shape, batch_size):\n","  \n","        self.g_input_shape = g_input_shape\n","        self.d_input_shape = d_input_shape\n","        self.d_output_shape, d_params = self.d['init'](prng_d, (batch_size, *d_input_shape))\n","        self.g_output_shape, g_params = self.g['init'](prng_g, (batch_size, *g_input_shape))\n","        self.batch_size = batch_size\n","        d_state = self.d_opt['init'](d_params)\n","        g_state = self.g_opt['init'](g_params)\n","        return d_state, g_state\n","\n","    @partial(jit, static_argnums=(0,))\n","    def _d_loss(self, d_params, g_params, z, real_samples):\n","        fake_imgs = self.g['apply'](g_params, z)\n","\n","        fake_predictions = self.d['apply'](d_params, fake_imgs)\n","        real_predictions = self.d['apply'](d_params, real_samples)\n","        fake_loss = self.loss_function(fake_predictions, jnp.zeros_like(fake_predictions))\n","        real_loss = self.loss_function(real_predictions, jnp.ones_like(real_predictions))\n","\n","        return fake_loss + real_loss\n","\n","    @partial(jit, static_argnums=(0, 4))\n","    def _g_loss(self, g_params, d_params, z, k):\n","        \"\"\"\n","        Warning if k is negative, batch_size - k bottom samples are used to calculate error\n","        Note: You can adjust this method to perform random or bottom updates\n","        \"\"\"\n","        fake_imgs = self.g['apply'](g_params, z)\n","\n","        fake_predictions = self.d['apply'](d_params, fake_imgs)\n","        fake_predictions = sort(fake_predictions, 0)\n","        if k > 0:\n","            fake_predictions = jnp.flip(fake_predictions, 0)\n","        # fake_predictions = jnp.flip(fake_predictions, 0)\n","        fake_predictions = fake_predictions[:k]\n","\n","        loss = self.loss_function(fake_predictions, jnp.ones_like(fake_predictions))\n","\n","        return loss\n","\n","    @partial(jit, static_argnums=(0, 6))\n","    def train_step(self, i, prng_key, d_state, g_state, real_samples, k):\n","\n","        k = k or self.batch_size\n","        prng1, prng2 = random.split(prng_key, 2)\n","        d_params = self.d_opt['get_params'](d_state)\n","        g_params = self.g_opt['get_params'](g_state)\n","\n","        z = random.normal(prng1, (self.batch_size, *self.g_input_shape))\n","        d_loss_value, d_grads = value_and_grad(self._d_loss)(d_params, g_params, z, real_samples)\n","        d_state = self.d_opt['update'](i, d_grads, d_state)\n","\n","        z = random.normal(prng2, (self.batch_size, *self.g_input_shape))\n","        g_loss_value, g_grads = value_and_grad(self._g_loss)(g_params, d_params, z, k)\n","        g_state = self.g_opt['update'](i, g_grads, g_state)\n","\n","        return d_state, g_state, d_loss_value, g_loss_value\n","\n","    @partial(jit, static_argnums=(0,))\n","    def generate_samples(self, z, g_state):\n","        fakes = self.g['apply'](self.g_opt['get_params'](g_state), z)\n","        return fakes\n","\n","    @partial(jit, static_argnums=(0,))\n","    def rate_samples(self, samples, d_state):\n","        crit = self.d['apply'](self.d_opt['get_params'](d_state), samples)\n","        return crit\n","def BCE_from_logits(logits, targets):\n","    p = sigmoid(logits)\n","    loss_array = -jnp.log(jnp.where(p == 0, EPS, p)) * targets\\\n","                 - jnp.log(1 - jnp.where(p == 1, 1-EPSNEG, p)) * (1 - targets)\n","    return jnp.mean(loss_array)"],"metadata":{"id":"lPg2FWQOmwaX","executionInfo":{"status":"ok","timestamp":1652444569054,"user_tz":-60,"elapsed":982,"user":{"displayName":"Abhilash Scaria","userId":"11656765587102373654"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ad317402-3bd3-45d9-96a8-d6473157a8d7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/jax/experimental/optimizers.py:30: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead\n","  FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/jax/experimental/stax.py:30: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead\n","  FutureWarning)\n"]}]},{"cell_type":"code","source":["SEED_DEFAULT = 100\n","\n","\n","class DataLoader:\n","    def get_next_batch(self):\n","        pass\n","\n","\n","class GaussianMixture(DataLoader):\n","    @staticmethod\n","    def create_2d_mean_matrix(num_components):\n","        a = int(np.sqrt(num_components))\n","        while a < num_components:\n","            if num_components % a == 0:\n","                break\n","            a += 1\n","        b = num_components // a\n","        return np.array([[i, j] for i in range(-a // 2 + 1, a // 2 + 1, 1) for j in range(-b // 2 + 1, b // 2 + 1, 1)])\n","\n","    @staticmethod\n","    def create_2d_covariance_matrix(variance, num_components):\n","        return np.array([np.identity(2) * variance for _ in range(num_components)])\n","\n","    def __init__(self, prng, batch_size, num_modes=None, variance=None, means=None, covariances=None):\n","        self.prng = prng\n","        self.batch_size = batch_size\n","        if means is not None:\n","            self.means = means\n","            self.num_modes = len(means)\n","        else:\n","            self.means = self.create_2d_mean_matrix(num_modes)\n","            self.num_modes = num_modes\n","        if covariances is not None:\n","            self.covariances = covariances\n","        else:\n","            self.covariances = self.create_2d_covariance_matrix(variance, self.num_modes)\n","        assert self.means.shape[0] == self.covariances.shape[0], \"means and covariances must have equal length\"\n","        assert self.means.shape[1] == self.covariances.shape[1], \"means and covariances must have corresponding \" \\\n","                                                                 \"dimensionality \"\n","\n","    def get_next_batch(self):\n","        self.prng, counts_key, shuffle_key, *keys = random.split(self.prng, self.num_modes + 3)\n","        numbs, counts = np.unique(random.randint(counts_key, (self.batch_size,), 0, self.num_modes), return_counts=True)\n","        \n","        batch = []\n","        for i, comp_ind in enumerate(numbs):\n","            samples = random.multivariate_normal(keys[i], self.means[comp_ind], self.covariances[comp_ind],\n","                                                 (counts[i],), jnp.float32)\n","            batch.extend(samples)\n","        batch = np.array(batch)\n","        batch = batch[random.permutation(shuffle_key, len(batch)),]\n","        return batch\n","\n","    def get_iteration_samples(self, num_iter):\n","        self.prng, counts_key, shuffle_key, *keys = random.split(self.prng, self.num_modes + 3)\n","        numbs, counts = np.unique(random.randint(counts_key, (self.batch_size * num_iter,), 0, self.num_modes),\n","                                  return_counts=True)\n","        batches = []\n","        print(counts)\n","        for i, comp_ind in enumerate(numbs):\n","            print(f\"creating {i}th components: {self.means[comp_ind]}->{counts[i]}\")\n","            samples = random.multivariate_normal(keys[i], self.means[comp_ind], self.covariances[comp_ind],\n","                                                 (counts[i],), jnp.float32)\n","            batches.extend(samples)\n","        batches = np.array(batches)\n","        print(f\"shuffling\")\n","        batches = batches[random.permutation(shuffle_key, len(batches)),]\n","        batches = batches.reshape((num_iter, self.batch_size, self.means[1].size))\n","        return batches\n"],"metadata":{"id":"Ho5qsy-BH4sg","executionInfo":{"status":"ok","timestamp":1652444574095,"user_tz":-60,"elapsed":228,"user":{"displayName":"Abhilash Scaria","userId":"11656765587102373654"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def get_gaussian_mixture(batch_size, num_iters, components, variance, seed=SEED_DEFAULT,\n","                         save=True, from_file=True):\n","    prng = random.PRNGKey(seed)\n","\n","    path = f\"./temp/GaussianMixture-{components}-{variance}-{batch_size}-{num_iters}.npy\"\n","    if os.path.exists(path) and from_file:\n","        print(\"file exists\")\n","        data = np.load(path)\n","    else:\n","        print(\"file didn't exist, creating\")\n","        dl = GaussianMixture(prng, batch_size, components, variance)\n","        data = dl.get_iteration_samples(num_iters)\n","        # if save:\n","        #     np.save(path, data)\n","    return data"],"metadata":{"id":"sZonzpB1_uds","executionInfo":{"status":"ok","timestamp":1652444576976,"user_tz":-60,"elapsed":286,"user":{"displayName":"Abhilash Scaria","userId":"11656765587102373654"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def plot_samples_scatter(samples, samples2=None, samples_ratings=None, save_adr=None, show=True, cmap=None):\n","    X = samples[:, 0],\n","    Y = samples[:, 1]\n","    if samples_ratings is not None:\n","        cmap = cmap or 'cividis'\n","\n","    plt.scatter(X, Y, c=samples_ratings, alpha=0.2, cmap=cmap)\n","    if samples_ratings is not None:\n","        plt.colorbar()\n","\n","    if samples2 is not None:\n","        X2 = samples2[:, 0]\n","        Y2 = samples2[:, 1]\n","\n","        plt.scatter(X2, Y2, color='red', alpha=0.2)\n","\n","    if save_adr is not None:\n","        plt.savefig(save_adr)\n","    if show:\n","        plt.show()\n","    else:\n","        plt.clf()"],"metadata":{"id":"Fg2sMLLBBVm0","executionInfo":{"status":"ok","timestamp":1652444578660,"user_tz":-60,"elapsed":210,"user":{"displayName":"Abhilash Scaria","userId":"11656765587102373654"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from jax._src.lax.lax import top_k\n","\n","\n","# this is to raise exception when nans are created\n","JAX_DEBUG_NANS = True\n","config.update(\"jax_debug_nans\", True)\n","\n","\n","# ~~~~~~~~~~~ Stax GAN ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","dataset_default = 'gaussian_mixture'\n","seed_default = 20\n","num_components_default = 25\n","gaussian_variance_default = 0.0025\n","prior_dim_default = 2\n","\n","d_lr_default = 0.0001\n","d_momentum_default = 0.9\n","d_momentum2_default = 0.99\n","g_lr_default = 0.0001\n","g_momentum_default = 0.9\n","g_momentum2_default = 0.99\n","loss_function_default = BCE_from_logits\n","batch_size_default = 256\n","batch_size_min_default = 192\n","decay_rate_default = 0.99\n","\n","num_iter_default = 10000\n","\n","datasets = {'gaussian_mixture':get_gaussian_mixture}\n","\n","\n","def create_and_initialize_gan(prng, d_lr, d_momentum, d_momentum2, g_lr, g_momentum, g_momentum2, loss_function,\n","                              d_input_shape, g_input_shape, batch_size):\n","    d_creator = mlp_discriminator\n","    g_creator = mlp_generator_2d\n","    d_opt_creator = partial(adam, d_lr, d_momentum, d_momentum2)\n","    g_opt_creator = partial(adam, g_lr, g_momentum, g_momentum2)\n","\n","    gan = GAN(d_creator, g_creator, d_opt_creator, g_opt_creator, loss_function)\n","\n","    prng1, prng2 = jax.random.split(prng, 2)\n","    d_state, g_state = gan.init(prng1, prng2, d_input_shape, g_input_shape, batch_size)\n","    return gan, d_state, g_state\n","\n","\n","def train(num_components, variance=gaussian_variance_default,\n","          batch_size=batch_size_default,\n","          num_iter=num_iter_default,\n","          batch_size_min=batch_size_min_default,\n","          dataset=dataset_default, loss_function=loss_function_default,\n","          prior_dim=prior_dim_default, d_lr=d_lr_default, d_momentum=d_momentum_default,\n","          d_momentum2=d_momentum2_default, g_lr=g_lr_default, g_momentum=g_momentum_default,\n","          g_momentum2=g_momentum2_default, top_k=1,\n","          show_plots=True,\n","          save_adr_plots_folder=None,\n","          seed=seed_default\n","          ):\n","    prng = jax.random.PRNGKey(seed)\n","    im_shape = (2,)\n","    prng_to_use, prng = jax.random.split(prng, 2)\n","    gan, d_state, g_state = create_and_initialize_gan(prng_to_use,\n","                                                      d_lr, d_momentum, d_momentum2,\n","                                                      g_lr, g_momentum, g_momentum2,\n","                                                      loss_function, im_shape, (prior_dim,), batch_size)\n","    data = datasets[dataset](batch_size, num_iter, num_components, variance)\n","\n","    d_losses = []\n","    g_losses = []\n","\n","    prng_images, prng = jax.random.split(prng, 2)\n","    r = jax.random.normal(prng_images, (10000, prior_dim_default))\n","\n","    start_time = time.time()\n","    prev_time = time.time()\n","    k = batch_size\n","    for i, real_ims in enumerate(data):\n","        # print info and show results\n","        if i % 1000 == 0:\n","            print(f\"{i}/{num_iter} took {time.time() - prev_time}\")\n","            prev_time = time.time()\n","            fake_imgs = gan.generate_samples(r, g_state)\n","            save_adr_plot = None\n","            \n","            plot_samples_scatter(fake_imgs, real_ims,\n","                                 save_adr=save_adr_plot,\n","                                 samples_ratings=gan.rate_samples(fake_imgs, d_state),\n","                                 show=show_plots)\n","           \n","        \n","\n","        # ------------- actual training starts -----------------------------\n","        # decay k\n","        if top_k == 1 and i % 2000 == 1999:\n","            k = int(k * decay_rate_default)\n","            k = max(batch_size_min, k)\n","            print(f\"iter:{i}/{num_iter}, updated k: {k}\")\n","\n","        # train one step\n","        prng, prng_to_use = jax.random.split(prng, 2)\n","        d_state, g_state, d_loss_value, g_loss_value = gan.train_step(i, prng_to_use, d_state, g_state, real_ims, k)\n","        # ------------- actual training ends --------------------------------\n","\n","        # keep the iteration loss\n","        d_losses.append(d_loss_value)\n","        g_losses.append(g_loss_value)\n","\n","    print(f'finished, took{time.time() - start_time}')\n","    return d_losses, g_losses, d_state, g_state, gan"],"metadata":{"id":"h4wMTYR1_lEQ","executionInfo":{"status":"ok","timestamp":1652445241136,"user_tz":-60,"elapsed":198,"user":{"displayName":"Abhilash Scaria","userId":"11656765587102373654"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["d_losses, g_losses, d_state, g_state, gan = train(num_components=25,\n","                                                      batch_size=256, top_k = -1)"],"metadata":{"id":"C8eyqpKiTnCG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _get_random(num, seed):\n","    prng = jax.random.PRNGKey(seed)\n","    r = jax.random.normal(prng, (num, 2))\n","    return r\n","\n","\n","def eval_gauss(gan, d_state, g_state, num_modes, var, seed=0):\n","    r = _get_random(10000, seed)\n","    fake_samples = np.array(gan.generate_samples(r, g_state))\n","    modes = GaussianMixture.create_2d_mean_matrix(num_modes)\n","    sd = np.sqrt(var)\n","\n","    mode_inds, dists = _get_nearest_modes(fake_samples, modes)\n","    recovered_modes = np.unique(mode_inds[dists < 4 * sd])\n","    high_quality_samples = mode_inds[dists < 4 * sd]\n","    print(f\"num of recovered modes:{len(recovered_modes)}\")\n","    print(f\"high guality samples:{len(high_quality_samples) / len(dists) * 100} %\")\n","    print(f\"samples within sd: \"\n","          f\"[0,1):{len(dists[dists < sd]) / len(dists) * 100}, \"\n","          f\"[1,2):{len(dists[(dists >= sd) & (dists < sd * 2)]) / len(dists) * 100}, \"\n","          f\"[2,3):{len(dists[(dists >= sd * 2) & (dists < sd * 3)]) / len(dists) * 100}, \"\n","          f\"[3,4):{len(dists[(dists >= sd * 3) & (dists < sd * 4)]) / len(dists) * 100}, \"\n","          f\"[4,inf):{len(dists[(dists >= sd * 4)]) / len(dists) * 100}\")\n","\n","    mode, counts = np.unique(mode_inds[dists <= 0.2], return_counts=True)\n","    plt.bar(mode, counts)\n","    #plt.savefig(\"./distribution-of-high-quality-samples-per-mode\")\n","    plt.show()\n","\n","    return mode_inds, dists\n","\n","\n","def _get_nearest_modes(samples, modes):\n","    mode_inds = [-1 for _ in range(len(samples))]\n","    dists = [-1 for _ in range(len(samples))]\n","    for i, sample in enumerate(samples):\n","        mode_inds[i], dists[i] = _get_nearest_mode(sample, modes)\n","    return np.array(mode_inds), np.array(dists)\n","\n","\n","def _get_nearest_mode(sample, modes):\n","    dist = np.sqrt((sample[0] - modes[0][0]) ** 2 + (sample[1] - modes[0][1]) ** 2)\n","    mode_ind = 0\n","    for i, mode in enumerate(modes):\n","        d = np.sqrt((sample[0] - mode[0]) ** 2 + (sample[1] - mode[1]) ** 2)\n","        if d < dist:\n","            dist = d\n","            mode_ind = i\n","    return mode_ind, dist\n"],"metadata":{"id":"Gu1QZzPV0G_s","executionInfo":{"status":"ok","timestamp":1652445598050,"user_tz":-60,"elapsed":214,"user":{"displayName":"Abhilash Scaria","userId":"11656765587102373654"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["mode_index, dist = eval_gauss(gan, d_state, g_state, 25, 0.0025, seed=0)"],"metadata":{"id":"kgWvmGTb0RKL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","g_losses = np.reshape(np.array(g_losses), (-1,1))\n","i = np.arange(10000)\n","print(i)\n","plt.plot(i,g_losses)"],"metadata":{"id":"DVIYgF095Nwq"},"execution_count":null,"outputs":[]}]}